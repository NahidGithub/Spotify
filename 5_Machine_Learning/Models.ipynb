{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Model suggestions from Dr. Bengfort \n",
    "1) Stick with support vector machines and logistic regression\n",
    "2) Gaussian Naïve Bayes if features are normally distributed\n",
    "3) Multinomial naïve bayes if not normally distributed\n",
    "4) Bayesian classifiers are going to perform the worst – this can be are baseline\n",
    "5) stick with support vector machines and logistic regression to preserve the linearity of the features  in an understandable way (natural binary classifiers)\n",
    "6) if svc is taking too long then recommend just using Stochastic Gradient Descent or Linear SVC - should improve the performance of the support vector machine and when you are working with support vector machine, make sure your trying polynomial kernels in addition to linear kernels\n",
    "7 ) Don’t know if you would get good results from Random Forest and K Near Neighbors, Gradient Boosting – might want to try them \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "from s3 import get_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data(data):\n",
    "    df = pd.read_csv(data,sep='|')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "\n",
    "bucket = 's3ssp'\n",
    "\n",
    "train_data = data(get_file(s3,bucket,download_file='Analysis_Data/master_train_playlist.csv',rename_file = 'Data/train.csv'))\n",
    "test_data = data(get_file(s3,bucket,download_file='Analysis_Data/test_ssp.csv',rename_file = 'Data/test.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = train_data.reindex(sorted(train_data.columns), axis=1)\n",
    "df_test = test_data.reindex(sorted(test_data.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns=['playlist'#,'valence','danceability',\n",
    "                                 #'energy','acousticness'\n",
    "                                 ])\n",
    "\n",
    "df_test = df_test.drop(columns=['playlist'#,'valence','danceability',\n",
    "                      #'energy','acousticness'\n",
    "                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "acousticness        float64\n",
       "danceability        float64\n",
       "energy              float64\n",
       "instrumentalness    float64\n",
       "key                 float64\n",
       "liveness            float64\n",
       "loudness            float64\n",
       "mode                float64\n",
       "speechiness         float64\n",
       "target                int64\n",
       "tempo               float64\n",
       "time_signature      float64\n",
       "valence             float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>target</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001185</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1310</td>\n",
       "      <td>-10.7400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.04040</td>\n",
       "      <td>0</td>\n",
       "      <td>120.1130</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.023155</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.1155</td>\n",
       "      <td>-9.5715</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.03835</td>\n",
       "      <td>0</td>\n",
       "      <td>121.6830</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001006</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1475</td>\n",
       "      <td>-10.2155</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.03755</td>\n",
       "      <td>0</td>\n",
       "      <td>110.6130</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000153</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>-9.9190</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.03670</td>\n",
       "      <td>0</td>\n",
       "      <td>104.0955</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000338</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.1565</td>\n",
       "      <td>-9.0215</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.04775</td>\n",
       "      <td>0</td>\n",
       "      <td>116.8675</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instrumentalness  key  liveness  loudness  mode  speechiness  target  \\\n",
       "0          0.001185  5.0    0.1310  -10.7400   1.0      0.04040       0   \n",
       "1          0.023155  3.5    0.1155   -9.5715   1.0      0.03835       0   \n",
       "2          0.001006  5.0    0.1475  -10.2155   1.0      0.03755       0   \n",
       "3          0.000153  5.5    0.1700   -9.9190   1.0      0.03670       0   \n",
       "4          0.000338  5.5    0.1565   -9.0215   1.0      0.04775       0   \n",
       "\n",
       "      tempo  time_signature  \n",
       "0  120.1130             4.0  \n",
       "1  121.6830             4.0  \n",
       "2  110.6130             4.0  \n",
       "3  104.0955             4.0  \n",
       "4  116.8675             4.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9215601439736355"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticalRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "#RandomForestRegressor(n_estimators = 50)\n",
    "\n",
    "X = df_train[[col for col in df_train.columns if col != 'target']]\n",
    "\n",
    "y = df_train['target']\n",
    "\n",
    "#enc = OneHotEncoder(handle_unknown='ignore')\n",
    "#enc.fit(X)\n",
    "#enc.categories_\n",
    "\n",
    "\n",
    "#Support Vector Machine\n",
    "estimator = svm.SVC(gamma=.001)\n",
    "estimator.fit(X,y)\n",
    "estimator.predict(df_test)\n",
    "estimator.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adamgoldstein/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 12 features per sample; expecting 8",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-f8dd912504b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlogreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlogreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlogreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mlogreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \"\"\"\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0;32m--> 262\u001b[0;31m                              % (X.shape[1], n_features))\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
      "\u001b[0;31mValueError\u001b[0m: X has 12 features per sample; expecting 8"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X,y)\n",
    "logreg.predict(df_test)\n",
    "logreg.score(X,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mode = [Pipeline([\n",
    "    ('std', StandardScaler()),\n",
    "    ('reg'),LinearRegression(fit_intercept=False)\n",
    "    ]),\n",
    "    Pipeline([\n",
    "    ('std', StandardScaler()),\n",
    "    ('reg'),RandomForestRegressor(n_estimator=50)\n",
    "    ]),\n",
    "    Pipeline([\n",
    "    ('std', StandardScaler()),\n",
    "    ('reg'),MLPRegressor(hidden_layer_sizes=(100,100,100))\n",
    "    ]),\n",
    "    Pipeline([\n",
    "    ('std', RobustScaler()),\n",
    "    ('reg'),LinearRegression(fit_intercept=False)\n",
    "    ]),\n",
    "    Pipeline([\n",
    "    ('std', RobustScaler()),\n",
    "    ('reg'),RandomForestRegressor(n_estimator=50)\n",
    "    ]),\n",
    "    Pipeline([\n",
    "    ('std', RobustScaler()),\n",
    "    ('reg'),MLPRegressor(hidden_layer_sizes=(100,100,100))\n",
    "    ]),\n",
    "]\n",
    "\n",
    "\n",
    "#check_is_fitted(model,['support_fit_','support_','support_vectors_'])\n",
    "model.fit(X,y)\n",
    "model.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
