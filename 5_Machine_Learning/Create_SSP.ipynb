{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "import sklearn\n",
    "import yellowbrick\n",
    "import re\n",
    "import mglearn\n",
    "import boto3\n",
    "from s3 import get_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "lyrics = get_file(s3,'s3ssp',download_file='NLP_Data/master_lyrics_audio_features.csv',rename_file='nlp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(lyrics,sep='|',encoding='utf-8')\n",
    "df_demo = df.copy().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Control Panel - Hyper Parameters\n",
    "\n",
    "#Count Vectorizer\n",
    "max_features = 100 #500\n",
    "max_df = .10\n",
    "\n",
    "\n",
    "\n",
    "#LDA\n",
    "n_components = 5  #10\n",
    "\n",
    "\n",
    "#LDA Display\n",
    "display_n_chunks = 5 #5\n",
    "n_components = 5        #20\n",
    "n_words = 20       #5\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from yellowbrick.text import FreqDistVisualizer\n",
    "\n",
    "# Load the text data\n",
    "\n",
    "\n",
    "vect = CountVectorizer(max_features=max_features, max_df=max_df,stop_words='english')\n",
    "docs      = vect.fit_transform(df_demo['lyrics'])\n",
    "features   = vect.get_feature_names()\n",
    "\n",
    "visualizer = FreqDistVisualizer(features=features, orient='v',n=30)\n",
    "visualizer.fit(docs)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count Vectorizer\n",
    "vect = CountVectorizer(max_features=max_features, max_df=max_df,stop_words='english')\n",
    "X = vect.fit_transform(df_demo['lyrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "lda = LatentDirichletAllocation(n_components=n_components, learning_method=\"batch\",\n",
    "                                max_iter=15, random_state=0)\n",
    "\n",
    "\n",
    "# We build the model and transform the data in one step\n",
    "# Computing transform takes some time,\n",
    "# and we can save time by doing both at once\n",
    "\n",
    "document_topics = lda.fit_transform(X)\n",
    "\n",
    "print(\"lda.components_.shape: {}\".format(lda.components_.shape))\n",
    "\n",
    "# For each topic (a row in the components_), sort the features (ascending)\n",
    "# Invert rows with [:, ::-1] to make sorting descending\n",
    "sorting = np.argsort(lda.components_, axis=1)#[:, ::-1]\n",
    "\n",
    "\n",
    "# Get the feature names from the vectorizer\n",
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "# Print out the 10 topics:\n",
    "mglearn.tools.print_topics(topics=range(n_components), feature_names=feature_names,\n",
    "                           sorting=sorting, topics_per_chunk=display_n_chunks, n_words=n_words)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble Playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_playlist_elements(components=range(n_components), feature_names=feature_names,\n",
    "                           sorting=sorting, topics_per_chunk=display_n_chunks, n_words=n_words):\n",
    "    topics_words = []\n",
    "    \n",
    "    for i in range(0, len(components), topics_per_chunk):\n",
    "        # for each chunk:\n",
    "        these_topics = components[i: i + topics_per_chunk]\n",
    "        \n",
    "        for t in these_topics:\n",
    "            \n",
    "            topic_words = []\n",
    "            \n",
    "            for i in range(n_words):\n",
    "                \n",
    "                try:\n",
    "                    #print((\"{:<14}\" * len_this_chunk).format(\n",
    "                    #    *feature_names[sorting[these_topics, i]]))\n",
    "                    topics_words.append({'topic':f'topic{t}','word':feature_names[sorting[these_topics, i]][t]})\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "    return topics_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_elements = get_playlist_elements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_playlist_elements = pd.DataFrame(playlist_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_df_words = df_playlist_elements['word'].tolist()\n",
    "list_df_topics = set(df_playlist_elements['topic'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lyrics(lyrics,element,track_uri):\n",
    "    \n",
    "    if(lyrics.find(element)!= -1):\n",
    "        \n",
    "        return track_uri\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ssp(topics,words):\n",
    "    topics_words = df_playlist_elements.copy()\n",
    "    \n",
    "    df_lyrics = df_demo.copy()\n",
    "    \n",
    "    df_empty = pd.DataFrame()\n",
    "    \n",
    "    ssp = []\n",
    "    \n",
    "    #Set df_demo_ssp to topic number\n",
    "\n",
    "    topics_words = topics_words[(topics_words['topic']== f'topic{topic}')]\n",
    "    \n",
    "    df_demo_ssp_wordset = topics_words['word'].tolist()\n",
    "\n",
    "    for word in df_demo_ssp_wordset:\n",
    "        \n",
    "        df_empty[f'{word}'] = df_lyrics.apply(lambda x: find_lyrics(x['lyrics'],word,x['track_uri']),axis=1)\n",
    "\n",
    "\n",
    "\n",
    "    return df_empty\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takes 8 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ssp = []\n",
    "\n",
    "for topic in range(len(list_df_topics)):\n",
    "    \n",
    "    ssp = make_ssp(topic,list_df_words)\n",
    "\n",
    "    \n",
    "    df_ssp = ssp.dropna(how='all')\n",
    "    \n",
    "    for x in range(100):\n",
    "        \n",
    "        for col in df_ssp.columns:\n",
    "            \n",
    "            df_ssp_col = df_ssp[col].dropna(how='any')\n",
    "            \n",
    "            col_track_uri = df_ssp_col.sample(1).values\n",
    "            \n",
    "            list_ssp.append({'playlist':f'topic{topic}playlist{x}','track_uri':col_track_uri[0]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ssp = pd.DataFrame(list_ssp)\n",
    "\n",
    "df_sample_ssp = sample_ssp.merge(df_demo,left_on='track_uri',right_on='track_uri').groupby('playlist').median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_ssp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save test_ssp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_ssp.to_csv('test_ssp.csv',sep='|',index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below is Under Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization (Valence Curve, Energy Curve)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualize = df_sample_ssp[(df_sample_ssp['playlist']=='topic0playlist0')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualize.plot.line(x='valence',y='energy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Spotify Playlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import spotipy#authentication\n",
    "import spotipy.util as util#authentication\n",
    "from spotipy.oauth2 import SpotifyClientCredentials#authentication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cid = '049ade7215e54c63a2b628f3784dc407'\n",
    "secret = '5d30770120ad4dbbabbb5ce538110e05'\n",
    "redirect_uri = 'http://google.com/'\n",
    "username = 'name'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#Authentication\n",
    "\n",
    "scope = 'playlist-modify-private'\n",
    "token_playlist = util.prompt_for_user_token(username, scope, client_id=cid, client_secret=secret, redirect_uri=redirect_uri)\n",
    "\n",
    "if token_playlist:\n",
    "    \n",
    "    sp_playlist = spotipy.Spotify(auth=token_playlist)\n",
    "\n",
    "else:\n",
    "    \n",
    "    print(\"Can't get token for\", username)\n",
    "    \n",
    "#Authentication\n",
    "\n",
    "scope = 'user-read-private'\n",
    "\n",
    "token_user = util.prompt_for_user_token(username, scope, client_id=cid, client_secret=secret, redirect_uri=redirect_uri)\n",
    "\n",
    "if token_user:\n",
    "    sp_user = spotipy.Spotify(auth=token_user)\n",
    "else:\n",
    "    print(\"Can't get token for\", username)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def get_user_id(url):\n",
    "    try:\n",
    "        resp = requests.get(url,headers={'Authorization': 'Bearer ' + token_user},\n",
    "                             #data={\"name\": \"SSP\"}\n",
    "                           )\n",
    "        \n",
    "        resp.raise_for_status()\n",
    "        \n",
    "    except requests.exceptions.HTTPError as err:\n",
    "        \n",
    "        print(err)\n",
    "        \n",
    "    \n",
    "    response = resp.json()\n",
    "    userid = response['id']\n",
    "    \n",
    "    return userid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "user_id = get_user_id('https://api.spotify.com/v1/me')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "identification = user_id\n",
    "identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "playlist = sp_playlist.user_playlist_create(identification,'SSP_Ideal', public=False, description=\"Ideal SSP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "playlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "playlist_tracks = sp_playlist.user_playlist_add_tracks(identification,playlist['id'],make_playlist['track_uri'], position=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## unigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic {i}:\".format(i=topic_idx))\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "#How many words per topic\n",
    "no_top_words = 4\n",
    "display_topics(nmf, tfidf_feature_names, no_top_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
